"""
Align MEA TXT time series down to a target FPS (default 24) using rolling-mean smoothing
and linear interpolation.

Inputs:
  - Directory of TXT files named like: IDENTIFIER_YYYY-MM-DD_Interviewtype_MEA.txt
  - Excel file frame_info.xlsx with columns:
		Pseudonym, FPS BRFI, FPS STiP, FPS WF
The interpolation and downsampling is done according to:
- Rolling mean smoothing (pandas.rolling, only where source_fps > target_fps)
Original timestamps: T₀, T₁, …, T_{N−1}
Original values for some feature: X₀ … X_{N−1}
Window size: w_raw = ceil(source_fps / target_fps) ->> I enforce odd so we can center, for instance 30/24 --> 3
This operation outputs new feature values (Y) calculated as the mean of its neighbors; the values then need to be transformed onto the new timestep grid
This is done to smooth out jitters in the high frequency of the feature estimates

-- Time resampling (np.interp(new_timestep vector τ_k, old_timesteps T_i, values from rolling mean y))
Step = Δ = 1 / target_fps
Generate new relative times (new_timestep vector): τ_k = k · Δ, for k = 0, 1, …, K where K are the integers denoting the corresponding timestep
Z_k (new feature vectors) = Y_i + (Y{i+1} − Y_i) * (T'k − T_i) / (T{i+1} − T_i)
Y_i + (Y{i+1} − Y_i) --> how much does the new values change between two known points?
(T'k − T_i) / (T{i+1} − T_i) --> how far are these two points separated in time?

We thus compute a weighted average of the two smoothed neighbor values, weighted according to how far away the target value was between its neighbors.

python align_fps_mea.py --in /path/to/mea/txt/files --out /path/to/output --target-fps 24 --frame-info /path/to/frame_info.xlsx

the --in argument specifies the path where all the .txt files should be located
the --target-fps specifies the target fps rate
the --frame-info is the xlsx file that stores the fps rates from the .txt files
the --out is the path where you want the new, aligned files saved (a directory will be created, but you need to specify the path)
In addition an "align_fps_log.txt" is created which stores one line pr file designating if it was aligned or if it failed.

"""

from __future__ import annotations

import argparse
import shutil
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Optional, Tuple

import numpy as np
import pandas as pd


# ------------------------------
# Filename parsing
# ------------------------------

@dataclass(frozen=True)
class ParsedName:
	identifier: str
	interview_type: str  # e.g., Bindung | Personal | Wunder | etc.


def parse_identifier_and_type(path: Path) -> Optional[ParsedName]:
	"""Parse identifier and interview type from a filename.

	  IDENTIFIER_YYYY-MM-DD_Interviewtype_In.txt
	  IDENTIFIER_YYYY-MM-DD-Interviewtype-In.txt
	If the second-to-last token is 'geschnitten', the interview type is the token before it.
	"""
	name = path.name
	if name.lower().endswith(".txt"):
		name = name[:-4]
	# Some of the file names contains '-' delimiters ; make all --> '_'
	tokens = [tok for tok in name.replace("-", "_").split("_") if tok]
	if len(tokens) < 3:
		return None
	identifier = tokens[0]
	# Handle cases where the second-to-last token is 'geschnitten'; use the preceding token
	penultimate = tokens[-2].lower()
	if penultimate == "geschnitten":
		if len(tokens) < 4:
			return None
		interview_type = tokens[-3]
	else:
		interview_type = tokens[-2]
	return ParsedName(identifier=identifier.strip(), interview_type=interview_type.strip())


# ------------------------------
# Frame info (Excel) helpers
# ------------------------------

TYPE_TO_COLUMN = {
	"bindung": "FPS BRFI",
	"personal": "FPS STiP",
	"wunder": "FPS WF",
}


def normalize_type_for_column(t: str) -> Optional[str]:
	"""Map various interview type strings to the frame_info.xlsx column name.

	Returns the column name to use in the Excel ('FPS BRFI'/'FPS STiP'/'FPS WF').
	"""
	tl = t.strip().lower()
	if "bind" in tl:
		return TYPE_TO_COLUMN["bindung"]
	if tl.startswith("pers") or tl.startswith("st") or "personal" in tl:
		return TYPE_TO_COLUMN["personal"]
	if tl.startswith("wun") or "wf" in tl:
		return TYPE_TO_COLUMN["wunder"]
	return None


def load_frame_info(xlsx_path: Path) -> pd.DataFrame:
	df = pd.read_excel(xlsx_path)
	df.columns = [str(c).strip() for c in df.columns]
	df["Pseudonym"] = df["Pseudonym"].astype(str).str.strip()
	return df


def get_source_fps(frame_info: pd.DataFrame, identifier: str, interview_type: str) -> Optional[float]:
	col = normalize_type_for_column(interview_type)
	if col is None:
		return None
	row = frame_info.loc[frame_info["Pseudonym"].astype(str).str.strip() == str(identifier).strip()]
	if row.empty:
		return None
	val = row.iloc[0][col] #the corresponding fps rate for the identifier for the interview type
	fps = float(val)
	return fps


# ------------------------------
# Resampling logic for MEA TXT files
# ------------------------------

def resample_to_target_mea(df: pd.DataFrame, src_fps: float, target_fps: float = 24.0) -> pd.DataFrame:
	"""Resample MEA dataframe to target fps using rolling-mean smoothing plus interpolation.

	- Only the first two columns are resampled
	- Row index represents the frame number
	- First and second columns are the numeric features to resample
	- Returns a dataframe with the same two-column structure
	"""
	# Clean headers for whitespace
	df = df.copy()
	df.columns = [str(c).replace("\ufeff", "").strip() for c in df.columns]

	# Get the first two columns
	if len(df.columns) < 2:
		raise ValueError("MEA file must have at least 2 columns")
	
	col1 = df.columns[0]
	col2 = df.columns[1]

	# Frame numbers are the row indices
	df_sorted = df.reset_index(drop=True)
	frames_old = np.arange(len(df_sorted), dtype=float)
	
	# Convert frame numbers to time (in seconds) using source FPS
	times_old = frames_old / src_fps
	t0 = times_old[0]
	times_rel = times_old - t0  # original timesteps relative to start (should be 0-based)
	t_end = times_rel[-1]
	
	# Compute number of new frames and create the new timestep grid
	n_new = int(np.floor(t_end * target_fps)) + 1
	new_rel = np.arange(n_new, dtype=float) / float(target_fps)
	new_rel = np.round(new_rel, 6)

	# Determine smoothing window (odd, >=1) based on ratio between source and target FPS
	ratio = src_fps / float(target_fps)
	if ratio <= 1:
		window = 1  # if src_fps is smaller than target fps, don't do rolling mean
	else:
		window = int(np.ceil(ratio))
		if window % 2 == 0:
			window += 1

	# Process both columns
	interp_data = {}
	for col in [col1, col2]:
		series = pd.to_numeric(df_sorted[col], errors="coerce")
		series = series.interpolate(method="linear", limit_direction="both")
		
		if window > 1:
			series = series.rolling(window=window, min_periods=1, center=True).mean()
		
		y = series.to_numpy(dtype=float)
		mask = ~np.isnan(y)
		
		if not mask.any():
			interp_data[col] = np.full_like(new_rel, np.nan)
		else:
			if np.isnan(y).any():
				idx = np.arange(len(y), dtype=float)
				y = np.interp(idx, idx[mask], y[mask])
			interp_data[col] = np.interp(new_rel, times_rel, y)

	# Build output dataframe with original column names
	out_df = pd.DataFrame({
		col1: interp_data[col1],
		col2: interp_data[col2]
	})
	
	return out_df


# ------------------------------
# CLI glue
# ------------------------------

def process_directory(in_dir: Path, out_dir: Path, frame_info_xlsx: Path, target_fps: float = 24.0) -> None:
	"""Process all TXT files under in_dir recursively and write outputs preserving subfolders under out_dir.

	The output structure mirrors the input tree beneath a new parent folder (aligned_XXfps from main()).
	"""
	out_dir.mkdir(parents=True, exist_ok=True)
	log_path = out_dir / "align_fps_log.txt"
	with log_path.open("w", encoding="utf-8") as log_file:
		def log(msg: str) -> None:
			print(msg)
			log_file.write(msg + "\n")
			log_file.flush()

		frame_info = load_frame_info(frame_info_xlsx)
		txt_paths = sorted(p for p in in_dir.rglob("*.txt") if p.is_file())
		if not txt_paths:
			log(f"No TXT files found under {in_dir} (recursive)")
			return

		log(f"Processing {len(txt_paths)} file(s) to {target_fps} FPS (recursive)")

		for p in txt_paths:
			parsed = parse_identifier_and_type(p)
			if parsed is None:
				log(f"[skip] Cannot parse identifier/type from: {p.name}")
				continue

			src_fps = get_source_fps(frame_info, parsed.identifier, parsed.interview_type)
			if src_fps is None:
				log(
					f"[skip] Missing FPS for identifier='{parsed.identifier}', type='{parsed.interview_type}' in frame_info.xlsx"
				)
				continue

			try:
				# Read TXT file - assuming tab or whitespace delimited
				df = pd.read_csv(p, sep=r'\s+', header=None)
			except Exception as e:
				log(f"[skip] Failed to read {p.name}: {e}")
				continue

			# Always run resampling pipeline
			try:
				out_df = resample_to_target_mea(df, src_fps=src_fps, target_fps=target_fps)
			except Exception as e:
				log(f"[error] Resampling {p.name}: {e}")
				continue

			# Preserve subfolder structure beneath out_dir
			try:
				rel = p.relative_to(in_dir)
			except ValueError:
				# If for some reason p is not under in_dir, fall back to flat output
				rel = Path(p.name)
			out_path = out_dir / rel
			out_path.parent.mkdir(parents=True, exist_ok=True)
			try:
				# Write as space-delimited TXT file without index or header
				out_df.to_csv(out_path, sep=' ', index=False, header=False)
				log(f"[ok] {rel}: {src_fps} -> {target_fps} FPS (rows {len(df)} -> {len(out_df)})")
			except Exception as e:
				log(f"[error] Writing {out_path}: {e}")


def parse_args(argv: Optional[list[str]] = None) -> argparse.Namespace:
	ap = argparse.ArgumentParser(description="Downsample MEA TXT files to a target FPS using frame_info.xlsx metadata")
	ap.add_argument("--in", dest="in_dir", required=True, help="Input directory containing TXT files")
	ap.add_argument("--frame-info", dest="frame_info", required=True, help="Path to frame_info.xlsx")
	ap.add_argument("--out", dest="out_dir", required=True, default=None, help="Output directory for resampled TXT files")
	ap.add_argument("--target-fps", dest="target_fps", type=float, default=24.0, help="Target FPS (default: 24)")
	return ap.parse_args(argv)


def main(argv: Optional[list[str]] = None) -> int:
	args = parse_args(argv)
	in_dir = Path(args.in_dir).expanduser().resolve()
	out_dir_name = f"aligned_{args.target_fps}fps"
	out_dir = Path(args.out_dir).expanduser().resolve() / out_dir_name
	frame_info = Path(args.frame_info).expanduser().resolve()

	if not in_dir.exists() or not in_dir.is_dir():
		print(f"Input directory does not exist or is not a directory: {in_dir}")
		return 2
	if not frame_info.exists():
		print(f"Frame info Excel not found: {frame_info}")
		return 2

	process_directory(in_dir, out_dir, frame_info, target_fps=float(args.target_fps))
	return 0


if __name__ == "__main__":
	raise SystemExit(main())

#python align_fps_mea.py --in /path/to/mea/txt/files --frame-info /path/to/frame_info.xlsx --out /path/to/output --target-fps 24
